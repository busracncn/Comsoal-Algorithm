{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proje.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMA5Dimmy/XMIxsF4xuHa4g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/busracncn/comsoal-algorithm/blob/master/proje.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVIgA6n-W4mE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d470884-89d7-4289-a131-00c7872e17b8"
      },
      "source": [
        "!pip install -q install tensorflow\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 1514593873068867857, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14509932544\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 10137098330130584097\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri5rDsD1XX_k",
        "outputId": "035a79dc-95b4-4cc5-ab3f-8637b01aca7d"
      },
      "source": [
        "!python nlp.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'nlp.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAo6RCfuXZZF",
        "outputId": "dd0a0cec-a862-4aa8-a433-f7d7b8bb0c42"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUMpygOMXtfl"
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EIIc38dX3fm"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'drive/nlp')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZegZ5_oX5vr",
        "outputId": "8680c029-10d7-487b-ea5c-aaed5aac0439"
      },
      "source": [
        "!pip install -q emoji\n",
        "!pip install -q install nltk\n",
        "!pip install -q install textblob\n",
        "!pip install -q install spacy\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▊                              | 10 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20 kB 38.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 30 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 40 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 51 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 61 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 71 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 81 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 92 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 102 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 112 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 122 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 133 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 143 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 153 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 163 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 174 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 184 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 185 kB 10.0 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhqeAgdzYBFV",
        "outputId": "277b8b7a-5e79-4623-8d32-e02399451cec"
      },
      "source": [
        "!python3 drive/proje/nlp.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATAFRAME\n",
            "          id  ... target\n",
            "0         1  ...      1\n",
            "1         4  ...      1\n",
            "2         5  ...      1\n",
            "3         6  ...      1\n",
            "4         7  ...      1\n",
            "...     ...  ...    ...\n",
            "7608  10869  ...      1\n",
            "7609  10870  ...      1\n",
            "7610  10871  ...      1\n",
            "7611  10872  ...      1\n",
            "7612  10873  ...      1\n",
            "\n",
            "[7613 rows x 5 columns]\n",
            "Data shape: (7613, 5)\n",
            "Columns: Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n",
            "unique targets : [1 0]\n",
            "number of unique keywords: 222\n",
            "train missing values:\n",
            " id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "         id  ... target\n",
            "0         1  ...      1\n",
            "1         4  ...      1\n",
            "2         5  ...      1\n",
            "3         6  ...      1\n",
            "4         7  ...      1\n",
            "...     ...  ...    ...\n",
            "7608  10869  ...      1\n",
            "7609  10870  ...      1\n",
            "7610  10871  ...      1\n",
            "7611  10872  ...      1\n",
            "7612  10873  ...      1\n",
            "\n",
            "[61 rows x 5 columns]\n",
            "NaN                      61\n",
            "fatalities               45\n",
            "armageddon               42\n",
            "deluge                   42\n",
            "harm                     41\n",
            "                         ..\n",
            "forest%20fire            19\n",
            "epicentre                12\n",
            "threat                   11\n",
            "inundation               10\n",
            "radiation%20emergency     9\n",
            "Name: keyword, Length: 222, dtype: int64\n",
            "train missing values:\n",
            " id             0\n",
            "keyword        0\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "tragedy                  97\n",
            "fatalities               45\n",
            "armageddon               42\n",
            "deluge                   42\n",
            "sinking                  41\n",
            "                         ..\n",
            "forest%20fire            19\n",
            "epicentre                12\n",
            "threat                   11\n",
            "inundation               10\n",
            "radiation%20emergency     9\n",
            "Name: keyword, Length: 221, dtype: int64\n",
            "test set shape: (7613, 3)\n",
            "   id  ... target\n",
            "0   1  ...      1\n",
            "1   4  ...      1\n",
            "2   5  ...      1\n",
            "3   6  ...      1\n",
            "4   7  ...      1\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n",
            "<seaborn.axisgrid.FacetGrid object at 0x7efc832d6890>\n",
            "train pre-processing done\n",
            "Data shape: (3263, 4)\n",
            "Columns: Index(['id', 'keyword', 'location', 'text'], dtype='object')\n",
            "number of unique keywords: 222\n",
            "test missing values:\n",
            " id             0\n",
            "keyword       26\n",
            "location    1105\n",
            "text           0\n",
            "dtype: int64\n",
            "NaN                      26\n",
            "deluged                  23\n",
            "demolished               22\n",
            "rubble                   22\n",
            "obliteration             21\n",
            "                         ..\n",
            "fatalities                5\n",
            "forest%20fire             5\n",
            "radiation%20emergency     5\n",
            "inundation                4\n",
            "epicentre                 1\n",
            "Name: keyword, Length: 222, dtype: int64\n",
            "train missing values:\n",
            " id             0\n",
            "keyword        0\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "rescuers                 41\n",
            "deluged                  23\n",
            "rubble                   22\n",
            "demolished               22\n",
            "snowstorm                21\n",
            "                         ..\n",
            "forest%20fire             5\n",
            "fatalities                5\n",
            "radiation%20emergency     5\n",
            "inundation                4\n",
            "epicentre                 1\n",
            "Name: keyword, Length: 221, dtype: int64\n",
            "test set shape: (3263, 2)\n",
            "test pre-processing done\n",
            "pre-processing functions done\n",
            "pre-processing applying functions done\n",
            "train shape :  (7613, 3)\n",
            "test shape :  (3263, 2)\n",
            "vector transform done\n",
            "submission file okey\n",
            "train accuracy score: 0.8664127150926048\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89      4342\n",
            "           1       0.91      0.77      0.83      3271\n",
            "\n",
            "    accuracy                           0.87      7613\n",
            "   macro avg       0.88      0.85      0.86      7613\n",
            "weighted avg       0.87      0.87      0.86      7613\n",
            "\n",
            "<Figure size 800x800 with 1 Axes>\n",
            "<Figure size 640x480 with 2 Axes>\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}